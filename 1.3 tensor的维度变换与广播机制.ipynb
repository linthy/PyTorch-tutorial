{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor的维度变换\n",
    "常用于 对输入数据的尺寸调整，分为四种情况：\n",
    "1. 矩阵尺度变换 -- view / reshape 函数\n",
    "2. 维度通道挤压与展开 -- squeeze / unsqueeze 函数\n",
    "3. 维度通道数的扩展 -- expand / repeat 函数\n",
    "4. 维度位置的交换 -- transpose / permute 函数\n",
    "\n",
    "**需要注意的问题是，数据尺寸调整后再复原，若通道顺序有变换，则会出现数据被破坏，信息被污染的情况**\n",
    "\n",
    "### 广播机制\n",
    "pytorch中使用的广播机制，允许多维矩阵与不同维度的矩阵或向量直接运算  \n",
    "使用前提：首先是以末端维度为开始对齐;两个矩阵中，低维矩阵的匹配维度的通道数，必须与高维矩阵通道数相同或者是1通道。  \n",
    "即 A -->[4,3,28,28], B --> [3,1,1]，C -->[2,28,28], D -->[1]  \n",
    "首先末端对齐，再判断通道数是否相同或为1   \n",
    "A -->[4,3,28,28]  \n",
    "B -->......[3,1,1]  \n",
    "C -->..[2,28,28]  \n",
    "D -->............[1]   \n",
    "可见 A能和 B,D运算，不能与C运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img -- > [B,C,H,W]\n",
    "img = torch.rand(4,3,28,28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reshape 与view 完全相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 784])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 想拉直图像像素作为特征 【28,28】 --> 28*28\n",
    "img.view(img.size(0),img.size(1),-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 784])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape 函数与 view 函数通用，作用一样\n",
    "feature = img.reshape(4,3,-1)\n",
    "feature.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unsqueeze 与squeeze 是一对对称函数\n",
    "展开与压缩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "torch.Size([1, 3, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 给特征加一个偏差，这就要求bias的尺寸相匹配\n",
    "bias = torch.randn(3)\n",
    "print(bias.shape)\n",
    "bias = bias.unsqueeze(0).unsqueeze(-1)\n",
    "print(bias.shape)\n",
    "bias.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = feature + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解释 expand 与repeat 的不同\n",
    "repeat 是执行是复制操作数据，占用内存空间，且repeat（1,3,1）里面值的含义是复制多少次，如例子就是第二通道，复制3次，不管原本有多少通道数据。  \n",
    "expand 只有在用到该数据时才执行扩展，但只能针对通道数量是1的维度操作，expand（4,1,1），就是第一通道拓展成4个通道。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.3170],\n",
       "         [-1.3170],\n",
       "         [-1.3170]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma = torch.randn(1).squeeze(0).squeeze(-1)\n",
    "gamma.expand(1,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.3170],\n",
       "         [-1.3170],\n",
       "         [-1.3170]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma.repeat(1,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 28, 28])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 28, 28])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# img [B,C,H,W]--> [B,W,H,C] --> [B,n_elem] --> [B,C,H,W]\n",
    "img2 = img.transpose(1,3).contiguous().view(img.size(0),-1).view(4,3,28,28)\n",
    "img2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意这里，虽然通道数一样，但顺序变换后，数据就对不上了，输出为False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, dtype=torch.uint8)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.all(torch.eq(img,img2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### permute 与 transpose\n",
    "推荐使用permute，直接明了指定通道位置，transpose每次只能变换一次通道\n",
    "\n",
    "#### 解释congtiguous（）的作用\n",
    "当transpose（）函数打乱数据存储时，需要用contiguous（）来重新连接数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 28, 28])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img3 = img.transpose(1,3).contiguous().view(4,-1).view(4,28,28,3).transpose(1,3)\n",
    "img3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1, dtype=torch.uint8)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.all(torch.eq(img,img3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 28, 28, 3])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img4 = img.permute(0,2,3,1)\n",
    "img4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 广播机制\n",
    "意义，减少维度变换函数的调用和数据内存的占用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.randn(4,3,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = torch.rand(3,1,1)\n",
    "C = torch.rand(2,28,28)\n",
    "D = torch.rand(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 28, 28])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(A + B).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-19104834b0ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "(A+C).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 28, 28])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(A+D).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
